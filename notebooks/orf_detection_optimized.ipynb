{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260022dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from Bio.Seq import Seq\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')  \n",
    "from src.config import KNOWN_RBS_MOTIFS, START_CODONS, STOP_CODONS,  MIN_ORF_LENGTH, LENGTH_REFERENCE_BP\n",
    "from src.config import SCORE_WEIGHTS, START_CODON_WEIGHTS, START_SELECTION_WEIGHTS, FIRST_FILTER_THRESHOLD, SECOND_FILTER_THRESHOLD\n",
    "from functools import lru_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e10fe8",
   "metadata": {},
   "source": [
    "# ORIGINAL CODE FROM VERSION 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54560b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_purine_rich_regions(\n",
    "    sequence: str, \n",
    "    min_length: int = 4, \n",
    "    min_purine_content: float = 0.6\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Find purine-rich regions (A and G rich) in sequence.\"\"\"\n",
    "    purine_regions = []\n",
    "    \n",
    "    for start in range(len(sequence)):\n",
    "        for length in range(min_length, min(9, len(sequence) - start + 1)):\n",
    "            subseq = sequence[start:start + length]\n",
    "            \n",
    "            purines = subseq.count('A') + subseq.count('G')\n",
    "            purine_fraction = purines / length\n",
    "            \n",
    "            if purine_fraction >= min_purine_content:\n",
    "                purine_regions.append({\n",
    "                    'sequence': subseq,\n",
    "                    'start': start,\n",
    "                    'end': start + length,\n",
    "                    'purine_content': purine_fraction,\n",
    "                    'length': length\n",
    "                })\n",
    "    \n",
    "    return purine_regions\n",
    "\n",
    "\n",
    "def evaluate_spacing_score(spacing: int) -> float:\n",
    "    \"\"\"Evaluate spacing between RBS and start codon (optimal: 6-10 nt).\"\"\"\n",
    "    if 6 <= spacing <= 8:\n",
    "        return 3.0  # Optimal\n",
    "    elif 5 <= spacing <= 10:\n",
    "        return 2.5  # Very good\n",
    "    elif 4 <= spacing <= 12:\n",
    "        return 1.5  # Good\n",
    "    elif 3 <= spacing <= 14:\n",
    "        return 1.0  # Acceptable\n",
    "    else:\n",
    "        return 0.2  # Poor\n",
    "\n",
    "\n",
    "def score_motif_similarity(sequence: str) -> Tuple[float, str]:\n",
    "    \"\"\"Score sequence similarity to known RBS motifs.\"\"\"\n",
    "    best_score = 0.0\n",
    "    best_motif = None\n",
    "    \n",
    "    for motif in KNOWN_RBS_MOTIFS:\n",
    "        for offset in range(max(len(sequence), len(motif))):\n",
    "            matches = 0\n",
    "            total_positions = 0\n",
    "            \n",
    "            for i in range(len(sequence)):\n",
    "                motif_pos = i + offset\n",
    "                if 0 <= motif_pos < len(motif):\n",
    "                    total_positions += 1\n",
    "                    if sequence[i] == motif[motif_pos]:\n",
    "                        matches += 1\n",
    "            \n",
    "            if total_positions > 0:\n",
    "                similarity = matches / total_positions\n",
    "                \n",
    "                overlap_length = total_positions\n",
    "                motif_weight = len(motif) / 6.0  # AGGAGG gets weight 1.0\n",
    "                \n",
    "                score = similarity * overlap_length * motif_weight\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_motif = motif\n",
    "    \n",
    "    return best_score, best_motif\n",
    "\n",
    "\n",
    "def predict_rbs_simple(sequence: str, orf: Dict, upstream_length: int = 20) -> Dict:\n",
    "    \"\"\"Predict RBS using purine content, spacing, and motif similarity.\"\"\"\n",
    "    start_pos = orf['start']\n",
    "    \n",
    "    if start_pos < upstream_length:\n",
    "        return {\n",
    "            'rbs_score': -5.0,\n",
    "            'spacing_score': 0.0,\n",
    "            'motif_score': 0.0,\n",
    "            'best_sequence': None,\n",
    "            'best_motif': None,\n",
    "            'spacing': 0,\n",
    "            'position': 0\n",
    "        }\n",
    "\n",
    "    upstream_start = start_pos - upstream_length\n",
    "    upstream_seq = sequence[upstream_start:start_pos]\n",
    "    \n",
    "    purine_regions = find_purine_rich_regions(upstream_seq, min_length=4, min_purine_content=0.6)\n",
    "    \n",
    "    best_score = -5.0\n",
    "    best_prediction = None\n",
    "    \n",
    "    for region in purine_regions:\n",
    "        sd_candidate = region['sequence']\n",
    "        spacing = len(upstream_seq) - region['end']\n",
    "        \n",
    "        if spacing < 4 or spacing > 12:\n",
    "            continue\n",
    "        \n",
    "        spacing_score = evaluate_spacing_score(spacing)\n",
    "        motif_score, best_motif = score_motif_similarity(sd_candidate)\n",
    "        purine_bonus = (region['purine_content'] - 0.6) * 2.0\n",
    "        \n",
    "\n",
    "        combined_score = (\n",
    "            spacing_score * 2.0 +    \n",
    "            motif_score * 1.5 +      \n",
    "            purine_bonus             \n",
    "        )\n",
    "        \n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_prediction = {\n",
    "                'rbs_score': combined_score,\n",
    "                'spacing_score': spacing_score,\n",
    "                'motif_score': motif_score,\n",
    "                'best_sequence': sd_candidate,\n",
    "                'best_motif': best_motif,\n",
    "                'spacing': spacing,\n",
    "                'position': region['start'],\n",
    "                'purine_content': region['purine_content'],\n",
    "                'length': region['length']\n",
    "            }\n",
    "    \n",
    "    return best_prediction or {\n",
    "        'rbs_score': -5.0,\n",
    "        'spacing_score': 0.0,\n",
    "        'motif_score': 0.0,\n",
    "        'best_sequence': None,\n",
    "        'best_motif': None,\n",
    "        'spacing': 0,\n",
    "        'position': 0\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ORF DETECTION\n",
    "# =============================================================================\n",
    "\n",
    "def find_orfs_candidates(sequence: str, min_length: int = 100) -> List[Dict]:\n",
    "    \"\"\"Detect all ORF candidates with dual coordinates and RBS scores.\"\"\"\n",
    "    orfs = []\n",
    "    \n",
    "    sequences = [\n",
    "        ('forward', sequence),\n",
    "        ('reverse', str(Seq(sequence).reverse_complement()))\n",
    "    ]\n",
    "    seq_len = len(sequence)\n",
    "\n",
    "    print(\"Detecting ORFs and calculating RBS...\")\n",
    "\n",
    "    for strand_name, seq in sequences:\n",
    "        for frame in range(3):\n",
    "            active_starts = [] \n",
    "            \n",
    "            for i in range(frame, len(seq) - 2, 3):\n",
    "                codon = seq[i:i+3]\n",
    "                \n",
    "                if len(codon) != 3:\n",
    "                    break\n",
    "                \n",
    "                if codon in START_CODONS:\n",
    "                    active_starts.append((i, codon))\n",
    "                    \n",
    "                elif codon in STOP_CODONS and active_starts:\n",
    "                    for start_pos, start_codon in active_starts:\n",
    "                        orf_length = i + 3 - start_pos\n",
    "                        \n",
    "                        if orf_length >= min_length:\n",
    "                            # Create ORF with dual coordinates\n",
    "                            if strand_name == 'forward':\n",
    "                                orf = {\n",
    "                                    'start': start_pos + 1,\n",
    "                                    'end': i + 3,\n",
    "                                    'genome_start': start_pos + 1,\n",
    "                                    'genome_end': i + 3,\n",
    "                                    'length': orf_length,\n",
    "                                    'frame': frame,\n",
    "                                    'strand': 'forward',\n",
    "                                    'start_codon': start_codon,\n",
    "                                    'sequence': seq[start_pos:i+3]\n",
    "                                }\n",
    "                            else:  # reverse strand\n",
    "                                orf = {\n",
    "                                    'start': start_pos + 1,\n",
    "                                    'end': i + 3,\n",
    "                                    'genome_start': seq_len - (i + 3) + 1,\n",
    "                                    'genome_end': seq_len - start_pos,\n",
    "                                    'length': orf_length,\n",
    "                                    'frame': frame,\n",
    "                                    'strand': 'reverse',\n",
    "                                    'start_codon': start_codon,\n",
    "                                    'sequence': seq[start_pos:i+3]\n",
    "                                }\n",
    "                            \n",
    "                            # Calculate RBS for this ORF\n",
    "                            rbs_result = predict_rbs_simple(seq, orf, upstream_length=20)\n",
    "                            orf['rbs_score'] = rbs_result['rbs_score']\n",
    "                            orf['rbs_motif'] = rbs_result.get('best_motif')\n",
    "                            orf['rbs_spacing'] = rbs_result.get('spacing', 0)\n",
    "                            orf['rbs_sequence'] = rbs_result.get('best_sequence')\n",
    "                            \n",
    "                            orfs.append(orf)\n",
    "                    \n",
    "                    active_starts = []\n",
    "    \n",
    "    print(f\"Complete: {len(orfs):,} ORFs detected with RBS scores\")\n",
    "    return orfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcdc30",
   "metadata": {},
   "source": [
    "# NEW CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2021e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "# =============================================================================\n",
    "# RBS (RIBOSOME BINDING SITE) PREDICTION\n",
    "# =============================================================================\n",
    "\n",
    "def find_purine_rich_regions_new(\n",
    "    sequence: str, \n",
    "    min_length: int = 4, \n",
    "    min_purine_content: float = 0.6\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Find purine-rich regions using sliding window optimization.\"\"\"\n",
    "    purine_regions = []\n",
    "    seq_len = len(sequence)\n",
    "    \n",
    "    if seq_len < min_length:\n",
    "        return purine_regions\n",
    "    \n",
    "    is_purine = [1 if base in 'AG' else 0 for base in sequence]\n",
    "    \n",
    "    for start in range(seq_len):\n",
    "        max_length = min(9, seq_len - start + 1)\n",
    "        \n",
    "        if max_length > min_length:\n",
    "            purine_count = sum(is_purine[start:start + min_length])\n",
    "            \n",
    "            length = min_length\n",
    "            if length <= seq_len - start:\n",
    "                purine_fraction = purine_count / length\n",
    "                if purine_fraction >= min_purine_content:\n",
    "                    purine_regions.append({\n",
    "                        'sequence': sequence[start:start + length],\n",
    "                        'start': start,\n",
    "                        'end': start + length,\n",
    "                        'purine_content': purine_fraction,\n",
    "                        'length': length\n",
    "                    })\n",
    "            \n",
    "            for length in range(min_length + 1, max_length):\n",
    "                if start + length > seq_len:\n",
    "                    break\n",
    "                \n",
    "                purine_count += is_purine[start + length - 1]\n",
    "                \n",
    "                purine_fraction = purine_count / length\n",
    "                if purine_fraction >= min_purine_content:\n",
    "                    purine_regions.append({\n",
    "                        'sequence': sequence[start:start + length],\n",
    "                        'start': start,\n",
    "                        'end': start + length,\n",
    "                        'purine_content': purine_fraction,\n",
    "                        'length': length\n",
    "                    })\n",
    "    \n",
    "    return purine_regions\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def score_motif_similarity_new(sequence: str) -> Tuple[float, str]:\n",
    "    \"\"\"Score sequence similarity to known RBS motifs.\"\"\"\n",
    "    best_score = 0.0\n",
    "    best_motif = None\n",
    "    \n",
    "    for motif in KNOWN_RBS_MOTIFS:\n",
    "        for offset in range(max(len(sequence), len(motif))):\n",
    "            matches = 0\n",
    "            total_positions = 0\n",
    "            \n",
    "            for i in range(len(sequence)):\n",
    "                motif_pos = i + offset\n",
    "                if 0 <= motif_pos < len(motif):\n",
    "                    total_positions += 1\n",
    "                    if sequence[i] == motif[motif_pos]:\n",
    "                        matches += 1\n",
    "            \n",
    "            if total_positions > 0:\n",
    "                similarity = matches / total_positions\n",
    "                \n",
    "                overlap_length = total_positions\n",
    "                motif_weight = len(motif) / 6.0  \n",
    "                \n",
    "                score = similarity * overlap_length * motif_weight\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_motif = motif\n",
    "    \n",
    "    return best_score, best_motif\n",
    "\n",
    "\n",
    "def predict_rbs_simple_new(sequence: str, orf: Dict, upstream_length: int = 20) -> Dict:\n",
    "    \"\"\"Predict RBS using purine content, spacing, and motif similarity.\"\"\"\n",
    "    start_pos = orf['start']\n",
    "    \n",
    "    if start_pos < upstream_length:\n",
    "        return {\n",
    "            'rbs_score': -5.0,\n",
    "            'spacing_score': 0.0,\n",
    "            'motif_score': 0.0,\n",
    "            'best_sequence': None,\n",
    "            'best_motif': None,\n",
    "            'spacing': 0,\n",
    "            'position': 0\n",
    "        }\n",
    "\n",
    "    upstream_start = start_pos - upstream_length\n",
    "    upstream_seq = sequence[upstream_start:start_pos]\n",
    "    \n",
    "    purine_regions = find_purine_rich_regions_new(upstream_seq, min_length=4, min_purine_content=0.6)\n",
    "    \n",
    "    best_score = -5.0\n",
    "    best_prediction = None\n",
    "    \n",
    "    for region in purine_regions:\n",
    "        sd_candidate = region['sequence']\n",
    "        spacing = len(upstream_seq) - region['end']\n",
    "        \n",
    "        if spacing < 4 or spacing > 12:\n",
    "            continue\n",
    "        elif 6 <= spacing <= 8:\n",
    "            spacing_score= 3.0  # Optimal\n",
    "        elif 5 <= spacing <= 10:\n",
    "            spacing_score= 2.5  # good\n",
    "        elif 4 <= spacing <= 12:\n",
    "            spacing_score= 1.5  # ok\n",
    "        \n",
    "        motif_score, best_motif = score_motif_similarity_new(sd_candidate)\n",
    "        purine_bonus = (region['purine_content'] - 0.6) * 2.0\n",
    "        \n",
    "\n",
    "        combined_score = (\n",
    "            spacing_score * 2.0 +    \n",
    "            motif_score * 1.5 +      \n",
    "            purine_bonus             \n",
    "        )\n",
    "        \n",
    "        if combined_score > best_score:\n",
    "            best_score = combined_score\n",
    "            best_prediction = {\n",
    "                'rbs_score': combined_score,\n",
    "                'spacing_score': spacing_score,\n",
    "                'motif_score': motif_score,\n",
    "                'best_sequence': sd_candidate,\n",
    "                'best_motif': best_motif,\n",
    "                'spacing': spacing,\n",
    "                'position': region['start'],\n",
    "                'purine_content': region['purine_content'],\n",
    "                'length': region['length']\n",
    "            }\n",
    "    \n",
    "    return best_prediction or {\n",
    "        'rbs_score': -5.0,\n",
    "        'spacing_score': 0.0,\n",
    "        'motif_score': 0.0,\n",
    "        'best_sequence': None,\n",
    "        'best_motif': None,\n",
    "        'spacing': 0,\n",
    "        'position': 0\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ORF DETECTION\n",
    "# =============================================================================\n",
    "\n",
    "def find_orfs_candidates_new(sequence: str, min_length: int = 100) -> List[Dict]:\n",
    "    \"\"\"Detect all ORF candidates with dual coordinates and RBS scores.\"\"\"\n",
    "    \n",
    "    if hasattr(score_motif_similarity_new, 'cache_clear'):\n",
    "        score_motif_similarity_new.cache_clear()\n",
    "    \n",
    "    orfs = []\n",
    "    \n",
    "    reverse_seq = str(Seq(sequence).reverse_complement())\n",
    "    \n",
    "    sequences = [\n",
    "        ('forward', sequence),\n",
    "        ('reverse', reverse_seq)\n",
    "    ]\n",
    "    seq_len = len(sequence)\n",
    "\n",
    "    print(\"Detecting ORFs and calculating RBS...\")\n",
    "\n",
    "    for strand_name, seq in sequences:\n",
    "        for frame in range(3):\n",
    "            active_starts = [] \n",
    "            \n",
    "            for i in range(frame, len(seq) - 2, 3):\n",
    "                codon = seq[i:i+3]\n",
    "                \n",
    "                if len(codon) != 3:\n",
    "                    break\n",
    "                \n",
    "                if codon in START_CODONS:\n",
    "                    active_starts.append((i, codon))\n",
    "                    \n",
    "                elif codon in STOP_CODONS and active_starts:\n",
    "                    for start_pos, start_codon in active_starts:\n",
    "                        orf_length = i + 3 - start_pos\n",
    "                        \n",
    "                        if orf_length >= min_length:\n",
    "                            # Create ORF with dual coordinates\n",
    "                            if strand_name == 'forward':\n",
    "                                orf = {\n",
    "                                    'start': start_pos + 1,\n",
    "                                    'end': i + 3,\n",
    "                                    'genome_start': start_pos + 1,\n",
    "                                    'genome_end': i + 3,\n",
    "                                    'length': orf_length,\n",
    "                                    'frame': frame,\n",
    "                                    'strand': 'forward',\n",
    "                                    'start_codon': start_codon,\n",
    "                                    'sequence': seq[start_pos:i+3]\n",
    "                                }\n",
    "                            else:  # reverse strand\n",
    "                                orf = {\n",
    "                                    'start': start_pos + 1,\n",
    "                                    'end': i + 3,\n",
    "                                    'genome_start': seq_len - (i + 3) + 1,\n",
    "                                    'genome_end': seq_len - start_pos,\n",
    "                                    'length': orf_length,\n",
    "                                    'frame': frame,\n",
    "                                    'strand': 'reverse',\n",
    "                                    'start_codon': start_codon,\n",
    "                                    'sequence': seq[start_pos:i+3]\n",
    "                                }\n",
    "                            \n",
    "                            # Calculate RBS for this ORF\n",
    "                            rbs_result = predict_rbs_simple_new(seq, orf, upstream_length=20)\n",
    "                            orf['rbs_score'] = rbs_result['rbs_score']\n",
    "                            orf['rbs_motif'] = rbs_result.get('best_motif')\n",
    "                            orf['rbs_spacing'] = rbs_result.get('spacing', 0)\n",
    "                            orf['rbs_sequence'] = rbs_result.get('best_sequence')\n",
    "                            \n",
    "                            orfs.append(orf)\n",
    "                    \n",
    "                    active_starts = []\n",
    "    \n",
    "    print(f\"Complete: {len(orfs):,} ORFs detected with RBS scores\")\n",
    "    return orfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941894ab",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# SIMPLE COMPARISON: Original vs Optimized\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d33228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPTIMIZATION COMPARISON TEST\n",
      "================================================================================\n",
      "Testing 15 genomes\n",
      "Comparing: OLD (baseline) vs NEW (optimized)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Genome: NC_000913.3\n",
      "================================================================================\n",
      "Using cached: data\\full_dataset\\NC_000913.3.fasta\n",
      "Sequence: 4,641,652 bp\n",
      "[1/2] Testing NEW (optimized)... Detecting ORFs and calculating RBS...\n",
      "Complete: 176,315 ORFs detected with RBS scores\n",
      "24.60s - 176,315 ORFs\n",
      "\n",
      "[2/2] Testing OLD (baseline)... Detecting ORFs and calculating RBS...\n",
      "Complete: 176,315 ORFs detected with RBS scores\n",
      "90.53s - 176,315 ORFs\n",
      "\n",
      "Results match: YES\n",
      "Time saved: -65.93s (-268.0%)\n",
      "\n",
      "================================================================================\n",
      "Genome: NC_000964.3\n",
      "================================================================================\n",
      "Using cached: data\\full_dataset\\NC_000964.3.fasta\n",
      "Sequence: 4,215,606 bp\n",
      "[1/2] Testing NEW (optimized)... Detecting ORFs and calculating RBS...\n",
      "Complete: 139,046 ORFs detected with RBS scores\n",
      "15.50s - 139,046 ORFs\n",
      "\n",
      "[2/2] Testing OLD (baseline)... Detecting ORFs and calculating RBS...\n",
      "Complete: 139,046 ORFs detected with RBS scores\n",
      "50.94s - 139,046 ORFs\n",
      "\n",
      "Results match: YES\n",
      "Time saved: -35.44s (-228.6%)\n",
      "\n",
      "================================================================================\n",
      "Genome: NC_003197.2\n",
      "================================================================================\n",
      "Downloading NC_003197.2 from NCBI...\n",
      "  Downloaded: 4,996,334 bytes\n",
      "Sequence: 4,857,450 bp\n",
      "[1/2] Testing NEW (optimized)... Detecting ORFs and calculating RBS...\n",
      "Complete: 173,564 ORFs detected with RBS scores\n",
      "17.65s - 173,564 ORFs\n",
      "\n",
      "[2/2] Testing OLD (baseline)... Detecting ORFs and calculating RBS...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MULTI-GENOME OPTIMIZATION TEST (Old vs New Comparison)\n",
    "# ============================================================================\n",
    "\n",
    "from Bio import Entrez, SeqIO\n",
    "import time\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "# Import config\n",
    "from src.config import TEST_GENOMES\n",
    "\n",
    "# Import OPTIMIZED version from production\n",
    "from src.traditional_methods import find_orfs_candidates\n",
    "\n",
    "# The OLD version (find_orfs_candidates_new) should already be defined in your notebook\n",
    "# Make sure you have find_orfs_candidates_new with the OLD (unoptimized) code\n",
    "\n",
    "# CRITICAL: Set your email for NCBI\n",
    "Entrez.email = \"your.email@example.com\"  # CHANGE THIS!\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZATION COMPARISON TEST\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Testing {len(TEST_GENOMES)} genomes\")\n",
    "print(\"Comparing: OLD (baseline) vs NEW (optimized)\\n\")\n",
    "\n",
    "# Ensure data directory exists\n",
    "data_dir = Path('data/full_dataset')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for genome_id in TEST_GENOMES:\n",
    "    fasta_path = data_dir / f'{genome_id}.fasta'\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Genome: {genome_id}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Download if not exists\n",
    "    if not fasta_path.exists():\n",
    "        print(f\"Downloading {genome_id} from NCBI...\")\n",
    "        try:\n",
    "            handle = Entrez.efetch(\n",
    "                db=\"nucleotide\",\n",
    "                id=genome_id,\n",
    "                rettype=\"fasta\",\n",
    "                retmode=\"text\"\n",
    "            )\n",
    "            \n",
    "            with open(fasta_path, 'w') as f:\n",
    "                fasta_content = handle.read()\n",
    "                f.write(fasta_content)\n",
    "            handle.close()\n",
    "            \n",
    "            file_size = fasta_path.stat().st_size\n",
    "            print(f\"  Downloaded: {file_size:,} bytes\")\n",
    "            \n",
    "            if file_size < 100:\n",
    "                print(f\"  [ERROR] File too small, download may have failed\")\n",
    "                results.append({\n",
    "                    'genome': genome_id,\n",
    "                    'size': 0,\n",
    "                    'time_old': 0,\n",
    "                    'time_new': 0,\n",
    "                    'orfs_old': 0,\n",
    "                    'orfs_new': 0,\n",
    "                    'match': False,\n",
    "                    'status': 'DOWNLOAD FAILED'\n",
    "                })\n",
    "                continue\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  [ERROR] Download failed: {e}\")\n",
    "            results.append({\n",
    "                'genome': genome_id,\n",
    "                'size': 0,\n",
    "                'time_old': 0,\n",
    "                'time_new': 0,\n",
    "                'orfs_old': 0,\n",
    "                'orfs_new': 0,\n",
    "                'match': False,\n",
    "                'status': f'DOWNLOAD ERROR'\n",
    "            })\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Using cached: {fasta_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load genome\n",
    "        record = SeqIO.read(fasta_path, \"fasta\")\n",
    "        sequence = str(record.seq)\n",
    "        print(f\"Sequence: {len(sequence):,} bp\")\n",
    "        \n",
    "        # Test OLD (baseline) version from notebook\n",
    "        print(\"\\n[1/2] Testing OLD (baseline)...\", end=\" \", flush=True)\n",
    "        gc.collect()\n",
    "        start = time.perf_counter()\n",
    "        orfs_old = find_orfs_candidates(sequence, min_length=100)\n",
    "        time_old = time.perf_counter() - start\n",
    "        print(f\"{time_old:.2f}s - {len(orfs_old):,} ORFs\")\n",
    "        \n",
    "        # Test NEW (optimized) version from production\n",
    "        print(\"[2/2] Testing NEW (optimized)...\", end=\" \", flush=True)\n",
    "        gc.collect()\n",
    "        start = time.perf_counter()\n",
    "        orfs_new = find_orfs_candidates_new(sequence, min_length=100)\n",
    "        time_new = time.perf_counter() - start\n",
    "        print(f\"{time_new:.2f}s - {len(orfs_new):,} ORFs\")\n",
    "        \n",
    "        # Verify results match\n",
    "        orfs_match = len(orfs_old) == len(orfs_new)\n",
    "        \n",
    "        # Check RBS scores match (sample first 100)\n",
    "        rbs_match = True\n",
    "        if orfs_match:\n",
    "            sample_size = min(100, len(orfs_old))\n",
    "            for i in range(sample_size):\n",
    "                if orfs_old[i].get('rbs_score') != orfs_new[i].get('rbs_score'):\n",
    "                    rbs_match = False\n",
    "                    break\n",
    "        \n",
    "        match = orfs_match and rbs_match\n",
    "        \n",
    "        # Calculate improvement\n",
    "        saved = time_old - time_new\n",
    "        percent = (saved / time_old * 100) if time_old > 0 else 0\n",
    "        \n",
    "        print(f\"\\nResults match: {'YES' if match else 'NO'}\")\n",
    "        print(f\"Time saved: {saved:.2f}s ({percent:.1f}%)\")\n",
    "        \n",
    "        # Cache stats\n",
    "        try:\n",
    "            from src.traditional_methods import score_motif_similarity\n",
    "            if hasattr(score_motif_similarity, 'cache_info'):\n",
    "                cache_info = score_motif_similarity.cache_info()\n",
    "                if cache_info.hits + cache_info.misses > 0:\n",
    "                    hit_rate = cache_info.hits / (cache_info.hits + cache_info.misses) * 100\n",
    "                    print(f\"Cache hit rate: {hit_rate:.1f}%\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        results.append({\n",
    "            'genome': genome_id,\n",
    "            'size': len(sequence),\n",
    "            'time_old': time_old,\n",
    "            'time_new': time_new,\n",
    "            'orfs_old': len(orfs_old),\n",
    "            'orfs_new': len(orfs_new),\n",
    "            'saved': saved,\n",
    "            'percent': percent,\n",
    "            'match': match,\n",
    "            'status': 'SUCCESS' if match else 'MISMATCH'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  [ERROR] Processing failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        results.append({\n",
    "            'genome': genome_id,\n",
    "            'size': 0,\n",
    "            'time_old': 0,\n",
    "            'time_new': 0,\n",
    "            'orfs_old': 0,\n",
    "            'orfs_new': 0,\n",
    "            'saved': 0,\n",
    "            'percent': 0,\n",
    "            'match': False,\n",
    "            'status': 'PROCESSING ERROR'\n",
    "        })\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Genome':<20} {'Size (bp)':<12} {'Old (s)':<10} {'New (s)':<10} {'Saved':<10} {'%':<8} {'Match':<8} {'Status'}\")\n",
    "print(\"-\"*110)\n",
    "\n",
    "for r in results:\n",
    "    size_str = f\"{r['size']:,}\" if r['size'] > 0 else \"-\"\n",
    "    old_str = f\"{r['time_old']:.2f}\" if r['time_old'] > 0 else \"-\"\n",
    "    new_str = f\"{r['time_new']:.2f}\" if r['time_new'] > 0 else \"-\"\n",
    "    saved_str = f\"{r['saved']:.2f}\" if r.get('saved', 0) != 0 else \"-\"\n",
    "    percent_str = f\"{r['percent']:.1f}%\" if r.get('percent', 0) != 0 else \"-\"\n",
    "    match_str = \"✓\" if r['match'] else \"✗\"\n",
    "    \n",
    "    status_display = \"✓ OK\" if r['status'] == 'SUCCESS' else f\"✗ {r['status']}\"\n",
    "    print(f\"{r['genome']:<20} {size_str:>11} {old_str:>9} {new_str:>9} {saved_str:>9} {percent_str:>7} {match_str:^8} {status_display}\")\n",
    "\n",
    "# Calculate statistics for successful runs\n",
    "successful = [r for r in results if r['status'] == 'SUCCESS']\n",
    "failed = [r for r in results if r['status'] != 'SUCCESS']\n",
    "\n",
    "if successful:\n",
    "    total_time_old = sum(r['time_old'] for r in successful)\n",
    "    total_time_new = sum(r['time_new'] for r in successful)\n",
    "    total_saved = sum(r['saved'] for r in successful)\n",
    "    avg_percent = sum(r['percent'] for r in successful) / len(successful)\n",
    "    \n",
    "    print(f\"\\nStatistics ({len(successful)} successful):\")\n",
    "    print(f\"  Total time OLD: {total_time_old:.2f}s\")\n",
    "    print(f\"  Total time NEW: {total_time_new:.2f}s\")\n",
    "    print(f\"  Total saved: {total_saved:.2f}s\")\n",
    "    print(f\"  Average improvement: {avg_percent:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"VERDICT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if failed:\n",
    "    print(f\"\\n[WARNING] {len(failed)} genome(s) failed:\")\n",
    "    for r in failed:\n",
    "        print(f\"  - {r['genome']}: {r['status']}\")\n",
    "\n",
    "# Check if all successful runs have matching results\n",
    "all_match = all(r['match'] for r in successful)\n",
    "\n",
    "if len(successful) == len(TEST_GENOMES) and all_match:\n",
    "    print(\"\\n✓ All test genomes processed successfully\")\n",
    "    print(\"✓ All results identical between old and new\")\n",
    "    print(\"✓ Optimizations working correctly across all genomes\")\n",
    "    total_saved = sum(r['saved'] for r in successful)\n",
    "    avg_improvement = sum(r['percent'] for r in successful) / len(successful)\n",
    "    print(f\"✓ Performance: {avg_improvement:.1f}% faster on average ({total_saved:.1f}s saved total)\")\n",
    "    print(\"\\n[READY TO MERGE]\")\n",
    "elif len(successful) > 0 and all_match:\n",
    "    print(f\"\\n[MOSTLY SUCCESS] {len(successful)}/{len(TEST_GENOMES)} genomes passed\")\n",
    "    print(\"✓ All successful runs have matching results\")\n",
    "    print(\"Some failures may be download issues - review above\")\n",
    "    print(\"\\n[LIKELY READY TO MERGE - review failures]\")\n",
    "elif not all_match:\n",
    "    print(\"\\n✗ RESULTS DON'T MATCH - DO NOT MERGE\")\n",
    "    print(\"Old and new versions produce different results!\")\n",
    "    mismatched = [r for r in successful if not r['match']]\n",
    "    for r in mismatched:\n",
    "        print(f\"  - {r['genome']}: {r['orfs_old']} vs {r['orfs_new']} ORFs\")\n",
    "else:\n",
    "    print(\"\\n✗ All genomes failed - DO NOT MERGE\")\n",
    "    print(\"Fix errors before proceeding\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gene_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
